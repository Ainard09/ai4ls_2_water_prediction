{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba3e50c-2dcf-4b3f-8c20-eddcc0c23633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import re\n",
    "import traceback\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b516cf9-30d1-4e1a-b5ca-00dda5d3fb01",
   "metadata": {},
   "source": [
    "### Add Exogenous Features to Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d0efa7-e41d-4e38-a5a9-df285c9833c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_exogenous_features(main_dir, df_recursive_temp, folder_name, debugging=False):\n",
    "    \"\"\" Function to add exogenous features to the monthly groundwater level\n",
    "    Input:\n",
    "        main_dir(string): main directory that host the 487 temp processed data\n",
    "\n",
    "        df_recursive_temp(df): dataframe of temperature recursive results for 26 horizon\n",
    "\n",
    "        folder_name(string): name of the temperature preprocessed data folder\n",
    "\n",
    "        debugging(bool): indicate to process all files in the temperature preprocessed data folder\n",
    "    \n",
    "    Output:\n",
    "        None \n",
    "    \"\"\"\n",
    "    \n",
    "    val_col_name = \"gw-level\"\n",
    "    \n",
    "    folder_dir = path.join(main_dir, folder_name)\n",
    "    \n",
    "    print(\"> Processing --{}..\".format(folder_name))\n",
    "    \n",
    "    # create new directory for clean processed data\n",
    "    output_dir = path.join(main_dir, \"clean_processed_data\")\n",
    "    \n",
    "    try:\n",
    "        shutil.rmtree(output_dir)\n",
    "    except:\n",
    "        pass\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "    filenames = os.listdir(folder_dir)\n",
    "    for filename in filenames:\n",
    "\n",
    "        mp_num = filename.split(\".\")[0].split(\"-\")[-1]\n",
    "        \n",
    "        filepath = path.join(folder_dir, filename)\n",
    "        \n",
    "        # process only files (don't iterate over output dir)\n",
    "        if not path.isfile(filepath):\n",
    "            continue\n",
    "     \n",
    "        df = pd.read_csv(filepath)[[\"date\",\"gw-level\",\"temp\"]]\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        df_rescur_id = df_recursive_temp[[\"date\", mp_num]]\n",
    "        date_recur_results_dict = df_rescur_id.set_index(\"date\")[mp_num].to_dict()\n",
    "\n",
    "        # fill the temp nan with recursive results\n",
    "        df.loc[df['temp'].isna(), 'temp'] = df.loc[df['temp'].isna(), 'date'].map(date_recur_results_dict)\n",
    "    \n",
    "    \n",
    "        # add temp features\n",
    "        df['temp_roll_mean_1_year'] = df['temp'].rolling(12, closed='left').mean()\n",
    "        df['temp_roll_mean_2_year'] = df['temp'].rolling(24, closed='left').mean()\n",
    "        df['temp_roll_max_1_year'] = df['temp'].rolling(12, closed='left').max()\n",
    "        df['temp_roll_min_1_year'] = df['temp'].rolling(12, closed='left').min()\n",
    "\n",
    "        \n",
    "        # add calender features\n",
    "        df[\"month\"] = df[\"date\"].dt.month\n",
    "        df[\"year\"] = df[\"date\"].dt.year\n",
    "        df[\"quarter\"] = df[\"date\"].dt.quarter\n",
    "\n",
    "        # add season features\n",
    "        df[\"season\"] = df[\"date\"].dt.month.apply(get_season)\n",
    "        df[\"weather\"] = df[\"date\"].dt.month.apply(get_weather)\n",
    "        df[\"season\"] = df[\"season\"].astype(\"category\")\n",
    "        df[\"weather\"] = df[\"weather\"].astype(\"category\")\n",
    "        \n",
    "        # cyclic calender and seasonal features\n",
    "        month_cyclic = cyclical_encoded(df[\"month\"], cycle_length=24)\n",
    "        quarter_cyclic = cyclical_encoded(df[\"quarter\"], cycle_length=4)\n",
    "\n",
    "        # merge the df to the cyclic the features\n",
    "        df_exogenous_features = pd.concat([df,month_cyclic, quarter_cyclic], axis=1)\n",
    "\n",
    "        # add intereaction between exogenous varibles\n",
    "        transformer_poly = PolynomialFeatures(\n",
    "        degree           = 2,\n",
    "        interaction_only = True,\n",
    "        include_bias     = False\n",
    "        ).set_output(transform=\"pandas\")\n",
    "    \n",
    "        # pick columns for exgennous varibles for intereactions\n",
    "        copy_df = df_exogenous_features.copy()\n",
    "        copy_df.drop([\"season\",\"weather\",\"date\",val_col_name], axis=1, inplace=True)\n",
    "        poly_cols = copy_df.columns.tolist()\n",
    "    \n",
    "        poly_features = transformer_poly.fit_transform(df_exogenous_features[poly_cols].dropna())\n",
    "        poly_features = poly_features.drop(columns=poly_cols)\n",
    "        poly_features.columns = [f\"poly_{col}\" for col in poly_features.columns]\n",
    "        poly_features.columns = poly_features.columns.str.replace(\" \", \"_\")\n",
    "        df_exogenous_features = pd.concat([df_exogenous_features, poly_features], axis=1)\n",
    "\n",
    "        # Set the last 26 entries of the 'temp' column to 0.0\n",
    "        df_exogenous_features.loc[df_exogenous_features.index[-26:], 'gw-level'] = 0.0\n",
    "\n",
    "        df_exogenous_features.dropna(inplace=True)\n",
    "        df_exogenous_features['temp_roll_mean_1_year'] = df_exogenous_features['temp_roll_mean_1_year'].round(2)\n",
    "        df_exogenous_features['temp_roll_mean_2_year'] = df_exogenous_features['temp_roll_mean_2_year'].round(2)\n",
    "        df_exogenous_features.set_index(\"date\", inplace=True)\n",
    "        \n",
    "        # save processed data to file\n",
    "        out_filename = \"processed_{}\".format(filename)\n",
    "        file_path = path.join(output_dir, out_filename)\n",
    "        df_exogenous_features.to_csv(file_path)\n",
    "    \n",
    "        \n",
    "        # if debugging, process only one file from each sub dir \n",
    "        if debugging:\n",
    "            break\n",
    "        \n",
    "    print(\"\\t- Done!\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "873c4128-d8d9-49a0-8a2d-3a9594a342e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to map month to season for exogenous varibles\n",
    "def get_season(month):\n",
    "    if month in [3.0, 4.0, 5.0]:\n",
    "        return 'spring'\n",
    "    elif month in [6.0, 7.0, 8.0]:\n",
    "        return 'summer'\n",
    "    elif month in [9.0, 10.0, 11.0]:\n",
    "        return 'Fall'\n",
    "    else:  # months 12.0, 1.0, 2.0\n",
    "        return 'winter'\n",
    "\n",
    "# information from www.weatherspark.com site\n",
    "def get_weather(month):\n",
    "    if month in [1, 2, 12]:\n",
    "        return \"freezing\"\n",
    "    elif month in [3, 11]:\n",
    "        return \"cold\"\n",
    "    elif month in [4,10]:\n",
    "        return \"cool\"\n",
    "    elif month in [5, 6, 9]:\n",
    "        return \"comfortable\"\n",
    "    else: # 7 & 8\n",
    "        return \"warm\"\n",
    "\n",
    "def cyclical_encoded(data, cycle_length):\n",
    "    \"\"\" function to capture pattern on calender features \"\"\"\n",
    "\n",
    "    sin = np.sin(2 * np.pi * data/cycle_length)\n",
    "    cos = np.cos(2 * np.pi * data/cycle_length)\n",
    "    result =  pd.DataFrame({\n",
    "                  f\"{data.name}_sin\": sin,\n",
    "                  f\"{data.name}_cos\": cos\n",
    "              })\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317e743c-ebef-4f91-b87f-fb2d0e0870b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature recursive results and make date column datetime object\n",
    "recursive_path = \"/users/azeez/water_prediction/ai4ls_2_water_prediction/data/raw/df_submission_temp.csv\"\n",
    "df_recursive = pd.read_csv(recursive_path)\n",
    "df_recursive = df_recursive.rename(columns={\"Unnamed: 0\": \"date\"})\n",
    "df_recursive['date'] = pd.to_datetime(df_recursive['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a696cbcd-1569-43f8-be32-b784e4d0c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PROCESSING_DEBUGGING = False # False => process  all files   \n",
    "main_dir = \"/users/azeez/water_prediction/ai4ls_2_water_prediction/data/raw/\"\n",
    "folder_name = \"temp_processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f61cd618-8350-4dce-b501-6a13b733befe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Processing --temp_processed_data..\n",
      "\t- Done!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    add_exogenous_features(main_dir, df_recursive, folder_name, debugging=FILE_PROCESSING_DEBUGGING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "badcec6e-f931-44cd-a4b2-fefd35243e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of processed data : 487\n"
     ]
    }
   ],
   "source": [
    "# check if the data is 487 in total as given on the deliverables\n",
    "processed_data_dir = \"/users/azeez/water_prediction/ai4ls_2_water_prediction/data/raw/clean_processed_data\"\n",
    "files = os.listdir(processed_data_dir)\n",
    "print(f\" Number of processed data : {len(files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e8b0094-3545-4eb0-8a98-144f6c757d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check irregularity in the datetime rangeindex\n",
    "counter = 0\n",
    "filenames_with_fault = []\n",
    "for filename in files:\n",
    "    path = os.path.join(processed_data_dir, filename)\n",
    "    df = pd.read_csv(path)\n",
    "    df.set_index(\"date\", inplace=True)\n",
    "    df_total = len(df.index)\n",
    "    time_range = len(pd.date_range(start=df.index.min(), end=df.index.max(), freq='MS'))\n",
    "    if df_total != time_range:\n",
    "        counter += 1\n",
    "        filenames_with_fault.append(filename)\n",
    "\n",
    "print(counter)\n",
    "filenames_with_fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da68a18-19d0-4e69-a53c-070e7b349a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = len(files) \n",
    "split_files = total_files // 4\n",
    "\n",
    "index = processed_data_dir.find(\"/raw/\")\n",
    "outward_dir = processed_data_dir[:index + len('/raw/')]\n",
    "\n",
    "processed_data_1 = os.path.join(outward_dir, \"clean_processed_data_part1\")\n",
    "processed_data_2 = os.path.join(outward_dir, \"clean_processed_data_part2\")\n",
    "processed_data_3 = os.path.join(outward_dir, \"clean_processed_data_part3\")\n",
    "processed_data_4 = os.path.join(outward_dir, \"clean_processed_data_part4\")\n",
    "\n",
    "if not os.path.exists(processed_data_1):\n",
    "    os.mkdir(processed_data_1)\n",
    "    \n",
    "if not os.path.exists(processed_data_2):\n",
    "    os.mkdir(processed_data_2)\n",
    "\n",
    "if not os.path.exists(processed_data_3):\n",
    "    os.mkdir(processed_data_3)\n",
    "\n",
    "if not os.path.exists(processed_data_4):\n",
    "    os.mkdir(processed_data_4)\n",
    "    \n",
    "for i, filename in enumerate(files):\n",
    "    filepath = os.path.join(processed_data_dir, filename)\n",
    "    if i <= split_files:\n",
    "        new_filepath = os.path.join(processed_data_1, filename)\n",
    "        shutil.copy(filepath, new_filepath)\n",
    "    elif i > split_files and i <= split_files*2:\n",
    "        new_filepath = os.path.join(processed_data_2, filename)\n",
    "        shutil.copy(filepath, new_filepath)\n",
    "    elif i > split_files and i <= split_files*3:\n",
    "        new_filepath = os.path.join(processed_data_3, filename)\n",
    "        shutil.copy(filepath, new_filepath)\n",
    "    else:\n",
    "        new_filepath = os.path.join(processed_data_4, filename)\n",
    "        shutil.copy(filepath, new_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2656ef-9821-4fc1-b7e0-f89a4bb0c770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7923bc-ee7d-4f79-97bd-e4a70529d5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
