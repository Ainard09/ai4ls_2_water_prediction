{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce8f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from os import path\n",
    "import re\n",
    "import glob as glob\n",
    "import shutil as shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to print full traceback in cought exceptions\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d293fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ehyd_messstellen_1_gw_Burgenland',\n",
       " 'ehyd_messstellen_2_gw_Kärnten',\n",
       " 'ehyd_messstellen_3_gw_Niederösterreich',\n",
       " 'ehyd_messstellen_4_gw_Oberösterreich',\n",
       " 'ehyd_messstellen_5_gw_Salzburg',\n",
       " 'ehyd_messstellen_6_gw_Steiermark',\n",
       " 'ehyd_messstellen_7_gw_Tirol',\n",
       " 'ehyd_messstellen_8_gw_Vorarlberg',\n",
       " 'ehyd_messstellen_9_gw_Wien']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regions from 1 to 9\n",
    "regions = [\n",
    "    \"Burgenland\",\n",
    "    \"Kärnten\",\n",
    "    \"Niederösterreich\",\n",
    "    \"Oberösterreich\",\n",
    "    \"Salzburg\",\n",
    "    \"Steiermark\",\n",
    "    \"Tirol\",\n",
    "    \"Vorarlberg\",\n",
    "    \"Wien\"\n",
    "]\n",
    "\n",
    "region_dirs = [\"ehyd_messstellen_{0}_gw_{1}\".format(i + 1, regions[i]) for i in range(0,len(regions))]\n",
    "region_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61a3f9",
   "metadata": {},
   "source": [
    "# Create a DF for all Measuring Points\n",
    "### - Can be useful for data aggregation on geographical base -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7125ec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mp 305714 attrs: {'land_height': '121.76', 'mp_height': '122.76', 'bottom_line': '111.76', 't_measuring_depth': '8.00'}\n",
      "mp 300137 attrs: {'land_height': '154.76', 'mp_height': '154.76', 'bottom_line': '151.36', 't_measuring_depth': nan}\n"
     ]
    }
   ],
   "source": [
    "def get_num_from_str(string):\n",
    "    matches = re.findall(\"\\d+\\.\\d+\", string)\n",
    "    if len(matches):\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def get_mp_attrs(region, region_dir, mp_num):\n",
    "\n",
    "    mp_base_data_path = path.join(region_dir, \"Stammdaten\", \"Stammdaten-{0}.txt\".format(mp_num))\n",
    "    \n",
    "    land_height = np.nan\n",
    "    mp_height = np.nan\n",
    "    bottom_line = np.nan\n",
    "    t_measuring_depth = np.nan\n",
    "    \n",
    "    with open(mp_base_data_path, encoding='unicode_escape') as f:\n",
    "        for num, line in enumerate(f, 1):\n",
    "            if \"Geländehöhe\" in line:\n",
    "                land_height = get_num_from_str(line)\n",
    "                \n",
    "            elif \"Messpunkthöhe\" in line:\n",
    "                mp_height = get_num_from_str(line)\n",
    "                \n",
    "            elif \"Sohllage\" in line:\n",
    "                bottom_line = get_num_from_str(line)\n",
    "                \n",
    "            elif \"T-Messtiefe u.GOK\" in line:\n",
    "                t_measuring_depth = get_num_from_str(line)\n",
    "                \n",
    "                break # since it's always listed latest in the file\n",
    "    \n",
    "    mp = {\n",
    "        \"land_height\": land_height,\n",
    "        \"mp_height\": mp_height,\n",
    "        \"bottom_line\": bottom_line,\n",
    "        \"t_measuring_depth\": t_measuring_depth\n",
    "    }\n",
    "    \n",
    "    return mp\n",
    "\n",
    "\n",
    "# test\n",
    "region_idx = 0\n",
    "\n",
    "# try mp with full attr\n",
    "mp_num = 305714\n",
    "mp_attrs = get_mp_attrs(regions[region_idx], region_dirs[region_idx], mp_num = mp_num)\n",
    "print(\"mp {0} attrs:\".format(mp_num), mp_attrs)\n",
    "\n",
    "# try mp with missing attr -> np.nan in missed value\n",
    "mp_num = 300137\n",
    "mp_attrs = get_mp_attrs(regions[region_idx], region_dirs[region_idx], mp_num = mp_num)\n",
    "print(\"mp {0} attrs:\".format(mp_num), mp_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8689f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '125.76' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '126.66' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '108.29' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.00' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '504.19' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '505.19' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '499.91' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.75' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '146.23' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '147.33' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '136.91' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.70' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '358.98' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '359.88' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '347.69' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '11.10' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '433.38' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '434.14' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '426.14' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '7.04' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '294.44' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '295.54' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '289.14' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '4.90' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '540.74' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '541.69' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '529.19' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.10' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '438.72' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '439.55' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '426.13' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '11.17' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '157.89' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '158.89' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '147.50' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
      "/tmp/ipykernel_7499/3722866313.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.00' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dbmsnr</th>\n",
       "      <th>hzbnr01</th>\n",
       "      <th>region</th>\n",
       "      <th>land_height</th>\n",
       "      <th>mp_height</th>\n",
       "      <th>bottom_line</th>\n",
       "      <th>t_measuring_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>679020.30</td>\n",
       "      <td>448967.00</td>\n",
       "      <td>1002266</td>\n",
       "      <td>335588</td>\n",
       "      <td>Burgenland</td>\n",
       "      <td>125.76</td>\n",
       "      <td>126.66</td>\n",
       "      <td>108.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>643311.78</td>\n",
       "      <td>398158.79</td>\n",
       "      <td>1002285</td>\n",
       "      <td>335810</td>\n",
       "      <td>Burgenland</td>\n",
       "      <td>235.69</td>\n",
       "      <td>236.59</td>\n",
       "      <td>225.74</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>616039.28</td>\n",
       "      <td>341145.21</td>\n",
       "      <td>1002422</td>\n",
       "      <td>345876</td>\n",
       "      <td>Burgenland</td>\n",
       "      <td>234.06</td>\n",
       "      <td>234.86</td>\n",
       "      <td>228.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615420.17</td>\n",
       "      <td>341879.22</td>\n",
       "      <td>1002237</td>\n",
       "      <td>335299</td>\n",
       "      <td>Burgenland</td>\n",
       "      <td>238.18</td>\n",
       "      <td>238.28</td>\n",
       "      <td>233.38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>665124.60</td>\n",
       "      <td>430698.99</td>\n",
       "      <td>1002327</td>\n",
       "      <td>345256</td>\n",
       "      <td>Burgenland</td>\n",
       "      <td>116.99</td>\n",
       "      <td>117.54</td>\n",
       "      <td>114.65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>631609.35</td>\n",
       "      <td>485861.88</td>\n",
       "      <td>9002133</td>\n",
       "      <td>319749</td>\n",
       "      <td>Wien</td>\n",
       "      <td>157.12</td>\n",
       "      <td>157.07</td>\n",
       "      <td>142.07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>622685.15</td>\n",
       "      <td>480101.35</td>\n",
       "      <td>9002268</td>\n",
       "      <td>350074</td>\n",
       "      <td>Wien</td>\n",
       "      <td>187.09</td>\n",
       "      <td>187.94</td>\n",
       "      <td>175.89</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>633723.06</td>\n",
       "      <td>481067.86</td>\n",
       "      <td>9002260</td>\n",
       "      <td>350116</td>\n",
       "      <td>Wien</td>\n",
       "      <td>160.93</td>\n",
       "      <td>161.93</td>\n",
       "      <td>150.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>633459.50</td>\n",
       "      <td>482115.68</td>\n",
       "      <td>9002231</td>\n",
       "      <td>341438</td>\n",
       "      <td>Wien</td>\n",
       "      <td>154.76</td>\n",
       "      <td>155.71</td>\n",
       "      <td>145.15</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>638616.37</td>\n",
       "      <td>477397.45</td>\n",
       "      <td>9002120</td>\n",
       "      <td>313254</td>\n",
       "      <td>Wien</td>\n",
       "      <td>152.98</td>\n",
       "      <td>153.58</td>\n",
       "      <td>143.18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3791 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y   dbmsnr  hzbnr01      region land_height  \\\n",
       "0     679020.30  448967.00  1002266   335588  Burgenland      125.76   \n",
       "1     643311.78  398158.79  1002285   335810  Burgenland      235.69   \n",
       "2     616039.28  341145.21  1002422   345876  Burgenland      234.06   \n",
       "3     615420.17  341879.22  1002237   335299  Burgenland      238.18   \n",
       "4     665124.60  430698.99  1002327   345256  Burgenland      116.99   \n",
       "...         ...        ...      ...      ...         ...         ...   \n",
       "3786  631609.35  485861.88  9002133   319749        Wien      157.12   \n",
       "3787  622685.15  480101.35  9002268   350074        Wien      187.09   \n",
       "3788  633723.06  481067.86  9002260   350116        Wien      160.93   \n",
       "3789  633459.50  482115.68  9002231   341438        Wien      154.76   \n",
       "3790  638616.37  477397.45  9002120   313254        Wien      152.98   \n",
       "\n",
       "     mp_height bottom_line t_measuring_depth  \n",
       "0       126.66      108.29               NaN  \n",
       "1       236.59      225.74             10.00  \n",
       "2       234.86      228.06               NaN  \n",
       "3       238.28      233.38               NaN  \n",
       "4       117.54      114.65               NaN  \n",
       "...        ...         ...               ...  \n",
       "3786    157.07      142.07               NaN  \n",
       "3787    187.94      175.89               NaN  \n",
       "3788    161.93      150.93               NaN  \n",
       "3789    155.71      145.15              6.05  \n",
       "3790    153.58      143.18               NaN  \n",
       "\n",
       "[3791 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = []\n",
    "\n",
    "for i in range(len(regions)):\n",
    "    region = regions[i]\n",
    "    region_dir = region_dirs[i]\n",
    "    # mps: measurment points \n",
    "    df_mps_path = path.join(region_dir, \"messstellen_alle.csv\")\n",
    "    df_mps = pd.read_csv(df_mps_path, sep=\";\")\n",
    "    # filter to typ == 'gw' then del typ col\n",
    "    df_mps = df_mps.query(\"typ=='gw'\")\n",
    "    del df_mps[\"typ\"]\n",
    "    \n",
    "    df_mps[\"region\"] = region\n",
    "    \n",
    "    # for every mp in the region get attributes\n",
    "    # create attrs cols and init with np.nan\n",
    "    mp_attrs = [\"land_height\", \"mp_height\", \"bottom_line\", \"t_measuring_depth\"]\n",
    "    for mp_attr in mp_attrs:\n",
    "        df_mps[mp_attr] = np.nan\n",
    "    \n",
    "    # fill with values when available\n",
    "    for index, row in df_mps.iterrows():\n",
    "        mp_num = row[\"hzbnr01\"]\n",
    "        mp_attr_vals = get_mp_attrs(region, region_dir, mp_num = mp_num)\n",
    "        for mp_attr in mp_attrs:\n",
    "            df_mps.at[index, mp_attr] = mp_attr_vals[mp_attr]\n",
    "    \n",
    "    values.extend(df_mps.values.tolist())\n",
    "\n",
    "colnames = [\"x\", \"y\", \"dbmsnr\", \"hzbnr01\", \"region\"] + mp_attrs\n",
    "df_mps_all = pd.DataFrame(values, columns = colnames)\n",
    "df_mps_all[\"x\"] = df_mps_all[\"x\"].str.replace(\",\", \".\").astype(float)\n",
    "df_mps_all[\"y\"] = df_mps_all[\"y\"].str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "df_mps_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c13d664f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> df_mps_all Saved as .csv!\n"
     ]
    }
   ],
   "source": [
    "# Save to .csv\n",
    "df_mps_all.to_csv(\"df_mps_all.csv\", index=False)\n",
    "print(\"> df_mps_all Saved as .csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae61f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dbmsnr</th>\n",
       "      <th>hzbnr01</th>\n",
       "      <th>region</th>\n",
       "      <th>land_height</th>\n",
       "      <th>mp_height</th>\n",
       "      <th>bottom_line</th>\n",
       "      <th>t_measuring_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>679020.30</td>\n",
       "      <td>448967.00</td>\n",
       "      <td>1002266</td>\n",
       "      <td>335588</td>\n",
       "      <td>Burgenland</td>\n",
       "      <td>125.76</td>\n",
       "      <td>126.66</td>\n",
       "      <td>108.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>676735.27</td>\n",
       "      <td>448176.78</td>\n",
       "      <td>1002166</td>\n",
       "      <td>326074</td>\n",
       "      <td>Burgenland</td>\n",
       "      <td>129.25</td>\n",
       "      <td>129.95</td>\n",
       "      <td>117.80</td>\n",
       "      <td>11.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>675621.69</td>\n",
       "      <td>449296.94</td>\n",
       "      <td>1002176</td>\n",
       "      <td>326173</td>\n",
       "      <td>Burgenland</td>\n",
       "      <td>144.56</td>\n",
       "      <td>145.41</td>\n",
       "      <td>132.86</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>676006.48</td>\n",
       "      <td>445085.10</td>\n",
       "      <td>1002167</td>\n",
       "      <td>326082</td>\n",
       "      <td>Burgenland</td>\n",
       "      <td>122.92</td>\n",
       "      <td>123.37</td>\n",
       "      <td>114.65</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>678066.41</td>\n",
       "      <td>450372.91</td>\n",
       "      <td>1002250</td>\n",
       "      <td>335422</td>\n",
       "      <td>Burgenland</td>\n",
       "      <td>151.60</td>\n",
       "      <td>152.50</td>\n",
       "      <td>124.33</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>680848.55</td>\n",
       "      <td>452791.43</td>\n",
       "      <td>1002262</td>\n",
       "      <td>335547</td>\n",
       "      <td>Burgenland</td>\n",
       "      <td>126.94</td>\n",
       "      <td>127.74</td>\n",
       "      <td>108.76</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x          y   dbmsnr  hzbnr01      region land_height mp_height  \\\n",
       "0    679020.30  448967.00  1002266   335588  Burgenland      125.76    126.66   \n",
       "20   676735.27  448176.78  1002166   326074  Burgenland      129.25    129.95   \n",
       "56   675621.69  449296.94  1002176   326173  Burgenland      144.56    145.41   \n",
       "94   676006.48  445085.10  1002167   326082  Burgenland      122.92    123.37   \n",
       "121  678066.41  450372.91  1002250   335422  Burgenland      151.60    152.50   \n",
       "160  680848.55  452791.43  1002262   335547  Burgenland      126.94    127.74   \n",
       "\n",
       "    bottom_line t_measuring_depth  \n",
       "0        108.29               NaN  \n",
       "20       117.80             11.12  \n",
       "56       132.86               NaN  \n",
       "94       114.65              6.10  \n",
       "121      124.33             27.00  \n",
       "160      108.76              6.20  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use util fun to find all mps in a selected radius\n",
    "from utils_mps import find_mps_in_radius\n",
    "\n",
    "hzbnr01 = 335588\n",
    "# TODO: fine-tuning radius value to aggregate data for model training\n",
    "radius = 5000\n",
    "df_mps_rds = find_mps_in_radius(df_mps_all, hzbnr01, radius)\n",
    "df_mps_rds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754a805",
   "metadata": {},
   "source": [
    "# Process Single Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9f6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# know how many rows to skip in pd.read_csv\n",
    "def csv_find_skiprows(filepath, lookup):\n",
    "    skiprows = 0\n",
    "    # first know how many rows to skip in pd.read_csv. TO do this will open the file and look for \"Werte:\"\n",
    "    with open(filepath, encoding='unicode_escape') as f:\n",
    "        for num, line in enumerate(f, 1):\n",
    "            if lookup in line:\n",
    "                skiprows = num\n",
    "                # print(\"skiprows:\", skiprows)\n",
    "                break\n",
    "                \n",
    "    return skiprows\n",
    "\n",
    "def process_region_sub_dir(region, region_dir, folder_name, val_col_name, debugging=False):\n",
    "    \n",
    "    folder_dir = path.join(region_dir, folder_name)\n",
    "    \n",
    "    print(\"> Processing {0} - {1}..\".format(region, folder_name))\n",
    "    \n",
    "    # clean previous processing output\n",
    "    output_dir = path.join(folder_dir, \"processed_data\")\n",
    "    \n",
    "    try:\n",
    "        shutil.rmtree(output_dir)\n",
    "    except:\n",
    "        pass\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "    filenames = os.listdir(folder_dir)\n",
    "    for filename in filenames:\n",
    "        \n",
    "        filepath = path.join(folder_dir, filename)\n",
    "        \n",
    "        # process only files (don't iterate over output dir)\n",
    "        if not path.isfile(filepath):\n",
    "            continue\n",
    "        \n",
    "        # first know how many rows to skip in pd.read_csv. TO do this will open the file and look for \"Werte:\"\n",
    "        lookup = \"Werte:\"\n",
    "        skiprows = csv_find_skiprows(filepath, lookup)\n",
    "        \n",
    "        # load and process .csv file\n",
    "     \n",
    "        df = pd.read_csv(filepath, sep=\" ;\", header=None, skiprows=skiprows,\n",
    "                               encoding='unicode_escape')\n",
    "        \n",
    "        \n",
    "\n",
    "        # manipulate data splitting values into more possible regressors (e.g. date -> day, month, year)\n",
    "        df.columns = [\"date & time\", val_col_name, \"empty\"]\n",
    "        del df[\"empty\"]\n",
    "        \n",
    "        # remove rows with gaps (\"Lücke\")\n",
    "        df = df[~df[val_col_name].str.contains(\"Lücke\")]\n",
    "        \n",
    "        # clean data from white spaces\n",
    "        df[\"date & time\"] = df[\"date & time\"].str.replace(\"  \", \"\")\n",
    "        \n",
    "        df[[\"date\", \"time\"]] = df[\"date & time\"].str.split(\" \", expand=True)\n",
    "        df[[\"day\", \"month\", \"year\"]] = df[\"date\"].str.split(\".\", expand=True)\n",
    "        df[[\"hour\", \"minute\", \"second\"]] = df[\"time\"].str.split(\":\", expand=True)\n",
    "        # clean gw-level value and convert it to float\n",
    "        df[val_col_name] = df.apply(\n",
    "            lambda row: float(row[val_col_name].split(\" ;\")[0].replace(\",\", \".\"))\n",
    "            , axis=1\n",
    "        )\n",
    "        # rearrange cols\n",
    "        df = df[[\"date\", \"day\", \"month\", \"year\", \"time\", \"hour\", \"minute\", \"second\", val_col_name]]\n",
    "        \n",
    "        df.to_csv(path.join(output_dir, \"processed_{0}\".format(filename)), index=False)\n",
    "        \n",
    "        # if debugging, process only one file from each sub dir \n",
    "        if debugging:\n",
    "            break\n",
    "        \n",
    "    print(\"\\t- Done!\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43110eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_region_mps_summary(region, region_dir, debugging):\n",
    "    \n",
    "    summary_dir  = path.join(region_dir, \"Summary\")\n",
    "    \n",
    "    print(\"> Creating {0} Summary..\".format(region))\n",
    "    \n",
    "    # clean previous processing output   \n",
    "    try:\n",
    "        shutil.rmtree(summary_dir)\n",
    "    except:\n",
    "        pass\n",
    "    os.mkdir(summary_dir)\n",
    "    \n",
    "    try:\n",
    "        # get processed monthly water level files as starting point\n",
    "        prc_mnth_lvls_dir = path.join(region_dir, \"Grundwasserstand-Monatsmittel\", \"processed_data\")\n",
    "        mnth_lvls_filenames = os.listdir(prc_mnth_lvls_dir)\n",
    "        \n",
    "        for mnth_lvls_filename in mnth_lvls_filenames:\n",
    "            \n",
    "            mp_num = int(mnth_lvls_filename.split(\".\")[0].split(\"-\")[-1])\n",
    "            \n",
    "            if debugging:\n",
    "                mp_num = 305540 # override mp_num value to choose a mp that we have temperature data for\n",
    "                print(\"mp_num:\", mp_num)\n",
    "                \n",
    "            df = pd.read_csv(path.join(prc_mnth_lvls_dir, mnth_lvls_filename), sep=\",\")\n",
    "            \n",
    "            # add extra fields, init them as NaN, then try to fill them with values\n",
    "            # add field: yr_max\n",
    "            df[\"yr_max\"] = np.nan\n",
    "            \n",
    "            yr_max_fpath = path.join(region_dir, \"Grundwasserstand-Jahresmaxima\", \"processed_data\", \"processed_Grundwasserstand-Jahresmaxima-{0}.csv\".format(mp_num))\n",
    "            \n",
    "            if path.exists(yr_max_fpath):\n",
    "                \n",
    "                df_yr_max = pd.read_csv(yr_max_fpath, sep=\",\")[[\"year\", \"gw-level\"]]\n",
    "                \n",
    "                # set yr as index and create dict for O(1) search\n",
    "                # first drop rows with \"year\" val duplicates to avoid errors when creating index\n",
    "                df_len_before_drop = len(df_yr_max)\n",
    "                df_yr_max.drop_duplicates(subset=[\"year\"], inplace=True)\n",
    "                df_len_after_drop = len(df_yr_max)\n",
    "                if not df_len_before_drop == df_len_after_drop:\n",
    "                    n_dropped = df_len_before_drop - df_len_after_drop\n",
    "                    print(f'\\t* Grundwasserstand-Jahresmaxima dropped {n_dropped} duplicates in \"year\".')\n",
    "                    \n",
    "                df_yr_max.set_index(\"year\", inplace=True)\n",
    "                dct_yr_max = df_yr_max.to_dict('index')\n",
    "                \n",
    "                # impute missing yr_max values from monthly values\n",
    "                # find nan_years: the ears for which we don't have yr_max value\n",
    "                nan_years = [nan_year for nan_year in list(df.year.unique()) if nan_year not in dct_yr_max]\n",
    "                for nan_year in nan_years:\n",
    "                    yr_max_val = df.query(\"year==@nan_year\")[\"gw-level\"].max()\n",
    "                    dct_yr_max[nan_year] = {\"gw-level\": yr_max_val}\n",
    "                    \n",
    "                df[\"yr_max\"] = df.apply(\n",
    "                    lambda row: dct_yr_max[row[\"year\"]][\"gw-level\"] if row[\"year\"] in dct_yr_max else np.nan\n",
    "                    , axis=1)\n",
    "                \n",
    "                # free resources\n",
    "                del df_yr_max\n",
    "                del dct_yr_max\n",
    "                \n",
    "            # add field: yr_max_dist\n",
    "            df[\"yr_max_dist\"] = np.nan\n",
    "            \n",
    "            df[\"yr_max_dist\"] = df.apply(\n",
    "                lambda row: round(row[\"yr_max\"] - row[\"gw-level\"], 2) if not row[\"yr_max\"] == np.nan else np.nan\n",
    "                , axis=1)\n",
    "                \n",
    "            # add field: yr_min\n",
    "            df[\"yr_min\"] = np.nan\n",
    "            \n",
    "            yr_min_fpath = path.join(region_dir, \"Grundwasserstand-Jahresminima\", \"processed_data\", \"processed_Grundwasserstand-Jahresminima-{0}.csv\".format(mp_num))\n",
    "            \n",
    "            if path.exists(yr_min_fpath):\n",
    "                \n",
    "                df_yr_min = pd.read_csv(yr_min_fpath, sep=\",\")[[\"year\", \"gw-level\"]]\n",
    "                \n",
    "                # set yr as index and create dict for O(1) search\n",
    "                # first drop rows with \"year\" val duplicates to avoid errors when creating index\n",
    "                df_len_before_drop = len(df_yr_min)\n",
    "                df_yr_min.drop_duplicates(subset=[\"year\"], inplace=True)\n",
    "                df_len_after_drop = len(df_yr_min)\n",
    "                if not df_len_before_drop == df_len_after_drop:\n",
    "                    n_dropped = df_len_before_drop - df_len_after_drop\n",
    "                    print(f'\\t* Grundwasserstand-Jahresminima dropped {n_dropped} duplicates in \"year\".')\n",
    "                df_yr_min.set_index(\"year\", inplace=True)\n",
    "                dct_yr_min = df_yr_min.to_dict('index')\n",
    "                \n",
    "                # impute missing yr_min values from monthly values\n",
    "                # find nan_years: the ears for which we don't have yr_min value\n",
    "                nan_years = [nan_year for nan_year in list(df.year.unique()) if nan_year not in dct_yr_min]\n",
    "                for nan_year in nan_years:\n",
    "                    yr_min_val = df.query(\"year==@nan_year\")[\"gw-level\"].min()\n",
    "                    dct_yr_min[nan_year] = {\"gw-level\": yr_min_val}\n",
    "                \n",
    "                df[\"yr_min\"] = df.apply(\n",
    "                    lambda row: dct_yr_min[row[\"year\"]][\"gw-level\"] if row[\"year\"] in dct_yr_min else np.nan\n",
    "                    , axis=1)                \n",
    "                \n",
    "                # free resources\n",
    "                del df_yr_min\n",
    "                del dct_yr_min\n",
    "                \n",
    "            # add field: yr_min_dist\n",
    "            df[\"yr_min_dist\"] = np.nan\n",
    "            \n",
    "            df[\"yr_min_dist\"] = df.apply(\n",
    "                lambda row: round(row[\"gw-level\"] - row[\"yr_min\"], 2) if not row[\"yr_min\"] == np.nan else np.nan\n",
    "                , axis=1)\n",
    "                \n",
    "            # add fields: yr_avg, yr_avg_dist, yr_avg_abs(dist)\n",
    "            df[\"yr_avg\"] = np.nan\n",
    "            df[\"yr_avg_dist\"] = np.nan\n",
    "            df[\"yr_avg_abs(dist)\"] = np.nan\n",
    "            \n",
    "            df[\"yr_avg\"] = df.apply(\n",
    "                lambda row: round(row[\"yr_max\"] - row[\"yr_min\"], 2) if (not row[\"yr_max\"] == np.nan and not row[\"yr_min\"] == np.nan) else np.nan\n",
    "                , axis=1)\n",
    "            df[\"yr_avg_dist\"] = df.apply(\n",
    "                lambda row: row[\"gw-level\"] - row[\"yr_avg\"] if not row[\"yr_avg\"] == np.nan else np.nan\n",
    "                , axis=1)\n",
    "            df[\"yr_avg_abs(dist)\"] = df.apply(\n",
    "                lambda row: np.abs(row[\"yr_avg_dist\"]) if not row[\"yr_avg_dist\"] == np.nan else np.nan\n",
    "                , axis=1)\n",
    "            \n",
    "                \n",
    "            # add field: temp to add temperature (Celcius) to every monthly measurement if available   \n",
    "            df[\"temp\"] = np.nan\n",
    "            \n",
    "            mnth_temp_fpath = path.join(region_dir, \"Grundwassertemperatur-Monatsmittel\", \"processed_data\", \"processed_Grundwassertemperatur-Monatsmittel-{0}.csv\".format(mp_num))\n",
    "            \n",
    "            # not all mps have monthly temperature data, in this case we keep it as np.nan            \n",
    "            if path.exists(mnth_temp_fpath):\n",
    "\n",
    "                # time in both ds is 00:00:00, so I only care about the date\n",
    "                df_mnth_temp = pd.read_csv(mnth_temp_fpath, sep=\",\")[[\"date\", \"temp\"]]\n",
    "                df_mnth_temp.set_index(\"date\", inplace=True)\n",
    "                \n",
    "                df[\"temp\"] = df.apply(\n",
    "                    lambda row: df_mnth_temp.loc[row[\"date\"]][\"temp\"] if row[\"date\"] in df_mnth_temp.index else np.nan\n",
    "                    , axis=1)\n",
    "                \n",
    "                # free resources\n",
    "                del df_mnth_temp\n",
    "            \n",
    "            # drop [\"time\", \"hour\", \"minute\", \"second\"] cols since time is always 00:00:00\n",
    "            del df[\"time\"]\n",
    "            del df[\"hour\"]\n",
    "            del df[\"minute\"]\n",
    "            del df[\"second\"]\n",
    "            \n",
    "            # add mp attrs to each row\n",
    "            res_mp = df_mps_all.query(\"hzbnr01==@mp_num\").to_dict(\"records\")[0] # dict of colname-val of first found row\n",
    "            mp_attrs = [\"x\", \"y\", \"dbmsnr\", \"hzbnr01\", \"region\", \"land_height\", \"mp_height\",\n",
    "                        \"bottom_line\", \"t_measuring_depth\"]\n",
    "            attr_col_loc = 0 # add firsts attr at first col\n",
    "            for attr in mp_attrs:\n",
    "                df.insert(attr_col_loc, attr, res_mp[attr])\n",
    "                attr_col_loc += 1 #add next attr at next col\n",
    "            \n",
    "            \n",
    "            if debugging:\n",
    "                print(df)\n",
    "            \n",
    "            # save summary df\n",
    "            df_summary_path = path.join(summary_dir, \"Summary-{0}.csv\".format(mp_num))\n",
    "            df.to_csv(df_summary_path, sep=\",\", index = False)            \n",
    "                \n",
    "            # free resources\n",
    "            del df\n",
    "            \n",
    "            # if debugging, create summary file for only one mp \n",
    "            if debugging:\n",
    "                break\n",
    "            \n",
    "        \n",
    "    except Exception as ex:\n",
    "        print(\"[Error]\")\n",
    "        print(traceback.format_exc())\n",
    "        \n",
    "    print(\"\\t- Done!\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def process_region_files(region, region_dir):\n",
    "    \n",
    "    # process and manipulate region files into clean .csv files\n",
    "    FILE_PROCESSING_DEBUGGING = False # False => process  all files     \n",
    "    folder_names = [\n",
    "        \"Grundwasserstand-Jahresmaxima\",\n",
    "        \"Grundwasserstand-Jahresminima\",\n",
    "        \"Grundwasserstand-Monatsmittel\",\n",
    "        \"Grundwassertemperatur-Monatsmittel\"        \n",
    "    ]\n",
    "    \n",
    "    for folder_name in folder_names:\n",
    "        if not folder_name == \"Grundwassertemperatur-Monatsmittel\":\n",
    "            val_col_name = \"gw-level\"\n",
    "        else:\n",
    "            val_col_name = \"temp\"\n",
    "            \n",
    "        process_region_sub_dir(region, region_dir, folder_name, val_col_name, debugging=FILE_PROCESSING_DEBUGGING)\n",
    "        \n",
    "    # create summary files on monthly base\n",
    "    SUMMARY_Creating_DEBUGGING = False # False => create summary for all mps in region\n",
    "    create_region_mps_summary(region, region_dir, debugging=SUMMARY_Creating_DEBUGGING)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f7f19c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Processing Burgenland - Grundwasserstand-Jahresmaxima..\n",
      "\t- Done!\n",
      "> Processing Burgenland - Grundwasserstand-Jahresminima..\n",
      "\t- Done!\n",
      "> Processing Burgenland - Grundwasserstand-Monatsmittel..\n",
      "\t- Done!\n",
      "> Processing Burgenland - Grundwassertemperatur-Monatsmittel..\n",
      "\t- Done!\n",
      "> Creating Burgenland Summary..\n",
      "\t- Done!\n",
      "> Processing Kärnten - Grundwasserstand-Jahresmaxima..\n",
      "\t- Done!\n",
      "> Processing Kärnten - Grundwasserstand-Jahresminima..\n",
      "\t- Done!\n",
      "> Processing Kärnten - Grundwasserstand-Monatsmittel..\n",
      "\t- Done!\n",
      "> Processing Kärnten - Grundwassertemperatur-Monatsmittel..\n",
      "\t- Done!\n",
      "> Creating Kärnten Summary..\n",
      "\t- Done!\n",
      "> Processing Niederösterreich - Grundwasserstand-Jahresmaxima..\n",
      "\t- Done!\n",
      "> Processing Niederösterreich - Grundwasserstand-Jahresminima..\n",
      "\t- Done!\n",
      "> Processing Niederösterreich - Grundwasserstand-Monatsmittel..\n",
      "\t- Done!\n",
      "> Processing Niederösterreich - Grundwassertemperatur-Monatsmittel..\n",
      "\t- Done!\n",
      "> Creating Niederösterreich Summary..\n",
      "\t* Grundwasserstand-Jahresminima dropped 1 duplicates in \"year\".\n",
      "\t* Grundwasserstand-Jahresmaxima dropped 1 duplicates in \"year\".\n",
      "\t* Grundwasserstand-Jahresminima dropped 1 duplicates in \"year\".\n",
      "\t- Done!\n",
      "> Processing Oberösterreich - Grundwasserstand-Jahresmaxima..\n",
      "\t- Done!\n",
      "> Processing Oberösterreich - Grundwasserstand-Jahresminima..\n",
      "\t- Done!\n",
      "> Processing Oberösterreich - Grundwasserstand-Monatsmittel..\n",
      "\t- Done!\n",
      "> Processing Oberösterreich - Grundwassertemperatur-Monatsmittel..\n",
      "\t- Done!\n",
      "> Creating Oberösterreich Summary..\n",
      "\t* Grundwasserstand-Jahresmaxima dropped 1 duplicates in \"year\".\n",
      "\t- Done!\n",
      "> Processing Salzburg - Grundwasserstand-Jahresmaxima..\n",
      "\t- Done!\n",
      "> Processing Salzburg - Grundwasserstand-Jahresminima..\n",
      "\t- Done!\n",
      "> Processing Salzburg - Grundwasserstand-Monatsmittel..\n",
      "\t- Done!\n",
      "> Processing Salzburg - Grundwassertemperatur-Monatsmittel..\n",
      "\t- Done!\n",
      "> Creating Salzburg Summary..\n",
      "\t- Done!\n",
      "> Processing Steiermark - Grundwasserstand-Jahresmaxima..\n",
      "\t- Done!\n",
      "> Processing Steiermark - Grundwasserstand-Jahresminima..\n",
      "\t- Done!\n",
      "> Processing Steiermark - Grundwasserstand-Monatsmittel..\n",
      "\t- Done!\n",
      "> Processing Steiermark - Grundwassertemperatur-Monatsmittel..\n",
      "\t- Done!\n",
      "> Creating Steiermark Summary..\n",
      "\t* Grundwasserstand-Jahresminima dropped 1 duplicates in \"year\".\n",
      "\t* Grundwasserstand-Jahresminima dropped 1 duplicates in \"year\".\n",
      "\t- Done!\n",
      "> Processing Tirol - Grundwasserstand-Jahresmaxima..\n",
      "\t- Done!\n",
      "> Processing Tirol - Grundwasserstand-Jahresminima..\n",
      "\t- Done!\n",
      "> Processing Tirol - Grundwasserstand-Monatsmittel..\n",
      "\t- Done!\n",
      "> Processing Tirol - Grundwassertemperatur-Monatsmittel..\n",
      "\t- Done!\n",
      "> Creating Tirol Summary..\n",
      "\t- Done!\n",
      "> Processing Vorarlberg - Grundwasserstand-Jahresmaxima..\n",
      "\t- Done!\n",
      "> Processing Vorarlberg - Grundwasserstand-Jahresminima..\n",
      "\t- Done!\n",
      "> Processing Vorarlberg - Grundwasserstand-Monatsmittel..\n",
      "\t- Done!\n",
      "> Processing Vorarlberg - Grundwassertemperatur-Monatsmittel..\n",
      "\t- Done!\n",
      "> Creating Vorarlberg Summary..\n",
      "\t- Done!\n",
      "> Processing Wien - Grundwasserstand-Jahresmaxima..\n",
      "\t- Done!\n",
      "> Processing Wien - Grundwasserstand-Jahresminima..\n",
      "\t- Done!\n",
      "> Processing Wien - Grundwasserstand-Monatsmittel..\n",
      "\t- Done!\n",
      "> Processing Wien - Grundwassertemperatur-Monatsmittel..\n",
      "\t- Done!\n",
      "> Creating Wien Summary..\n",
      "\t- Done!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "    for region_idx in range(len(regions)):\n",
    "        region = regions[region_idx]\n",
    "        region_dir = region_dirs[region_idx]\n",
    "        process_region_files(region, region_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf45b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc4f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a527f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
